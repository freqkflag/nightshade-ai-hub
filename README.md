# ğŸ§  SnareDrop AI Hub

Welcome to **SnareDrop AI Hub** â€” your all-in-one, self-hosted AI stack powered by open models and terminal sorcery. This system gives you a local-first, Warp-like terminal AI assistant, real-time chat interfaces, flow-based automation tools, and full Ollama-backed LLM power â€” all running on your VPS.

> ğŸ” 100% Private | âš¡ï¸ Local Models | ğŸ§© Modular | â˜ ï¸ Warp-on-steroids for Linux nerds

![Status](https://img.shields.io/badge/status-live-green?style=for-the-badge&logo=vercel)
![License](https://img.shields.io/badge/license-Cyberpunk%20Copyleft-9c27b0?style=for-the-badge)
![Built%20for](https://img.shields.io/badge/built%20for-twist3dkinkst3r.com-ff1493?style=for-the-badge&logo=cloudflare)

![Ollama](https://img.shields.io/badge/Ollama-local--LLMs-4caf50?style=flat-square&logo=linux)
![OpenInterpreter](https://img.shields.io/badge/Interpreter-AI%20Shell-blueviolet?style=flat-square&logo=gnome-terminal)
![Flowise](https://img.shields.io/badge/Flowise-LLM%20Workflow-03a9f4?style=flat-square&logo=airflow)
![OpenWebUI](https://img.shields.io/badge/OpenWebUI-Chat%20Interface-e91e63?style=flat-square&logo=webcomponents)

![Docker](https://img.shields.io/badge/Dockerized-yes-2496ed?style=flat-square&logo=docker)
![Coolify](https://img.shields.io/badge/Coolify%20Ready-yes-ff5722?style=flat-square&logo=githubactions)
![Dokploy](https://img.shields.io/badge/Dokploy%20Compatible-yes-795548?style=flat-square&logo=nginx)




---

## ğŸ“¦ What's Inside

| Service           | Description                                                   | Port   |
|------------------|---------------------------------------------------------------|--------|
| ğŸ§  Ollama         | Local LLM model server (LLaMA3, Code Llama, Mistral, etc.)    | 11434  |
| ğŸ”® Open Interpreter | AI assistant that runs + explains terminal commands           | CLI    |
| ğŸ’¬ OpenWebUI      | ChatGPT-style web UI for local LLMs (Ollama, LocalAI, etc.)   | 3002   |
| ğŸ§  Flowise         | Drag-and-drop LLM app builder (LangChain-style workflows)     | 3003   |

---

## ğŸš€ Quick Start

1. Clone the repo:

```bash
git clone https://github.com/YOUR_USERNAME/snaredrop-ai-hub.git
cd snaredrop-ai-hub
````

2. Create your `.env` file:

```bash
cp .env.example .env
# (edit it as needed)
```

3. Launch the stack:

```bash
docker compose up -d
```

4. Pull a model (e.g. LLaMA3):

```bash
docker exec -it ollama ollama run llama3
```

5. Run Open Interpreter:

```bash
docker exec -it interpreter interpreter
```

---

## ğŸŒ Web Interfaces

| App       | URL                                                      |
| --------- | -------------------------------------------------------- |
| OpenWebUI | [http://your-server-ip:3002](http://your-server-ip:3002) |
| Flowise   | [http://your-server-ip:3003](http://your-server-ip:3003) |

> You can configure domains + HTTPS via Traefik, NGINX, or Cloudflare Tunnel.

---

## âš™ï¸ Config via `.env`

```env
OLLAMA_PORT=11434
OLLAMA_MODEL=llama3

INTERPRETER_MODEL=http://ollama:11434

OPENWEBUI_PORT=3002
FLOWISE_PORT=3003
```

---

## ğŸ“‚ Folder Structure

```
snaredrop-ai-hub/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ interpreter/             # Optional config for Open Interpreter
â””â”€â”€ README.md
```

---

## ğŸ›¡ Security & Isolation

* All traffic is internal or via your reverse proxy
* No cloud APIs required (unless you choose to)
* Easily integrate with **Cloudflare**, **NGINX**, or **Coolify**

---

## ğŸ“– Use Cases

* ğŸ§  Ask terminal questions & execute with Open Interpreter
* âœï¸ Write code, blog posts, or support replies using OpenWebUI
* ğŸ”Œ Chain workflows visually with Flowise
* ğŸ” Run fully local GPT-4-alternatives with Ollama

---

## ğŸ‘¨â€ğŸ’» Author

Made with ğŸ”¥ by [@freqkflag](https://github.com/freqkflag) aka **Joey King**
ğŸ“ Austin, TX
ğŸ•¸ï¸ [cultofjoey.com](https://cultofjoey.com) â€¢ [twist3dkinkst3r.com](https://twist3dkinkst3r.com)

---

## ğŸ§ª Future Add-Ons

* [ ] PrivateGPT for querying local docs
* [ ] Supabase for memory/persistence
* [ ] Web terminal with LLM assistance
* [ ] VS Code integration
* [ ] Custom Ollama UIs (kinky/cyberpunk themes ğŸ˜ˆ)

---

## ğŸ§  License

This project is licensed under the **Cyberpunk Copyleft**.
Use it. Break it. Hack it. Just donâ€™t gatekeep it.


